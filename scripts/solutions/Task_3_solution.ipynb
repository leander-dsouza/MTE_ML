{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.10 64-bit"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "Task_3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Task 3"
      ],
      "metadata": {
        "id": "frank-statistics"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Assignment task\n",
        "<pre>\n",
        "Download data from <a href='https://tinyurl.com/ym6xcth4'>link</a>\n",
        "\n",
        "1. Build a feature Matrix using TF-Idf_A method\n",
        "2. Fit the Log Regression Classifier and get Accuracy, Precision, Recall and AUC Score\n",
        "3. Compare the results with Naive Bayes\n",
        "4. Write your observations\n",
        "\n",
        "</pre>\n"
      ],
      "metadata": {
        "id": "involved-integrity"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://i.imgur.com/ELUAXGn.png'>"
      ],
      "metadata": {
        "id": "rQBlDBEJBObb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Build a feature Matrix using TF-IDF method"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1a. Preprocessing"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1a.1 Reading the first dataset"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "\n",
        "df_A = pd.read_csv('../../datasets/Tweets.csv')\n",
        "\n",
        "df_A\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_created</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.703060e+17</td>\n",
              "      <td>neutral</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>24-02-2015 11:35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.703010e+17</td>\n",
              "      <td>positive</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>24-02-2015 11:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.703010e+17</td>\n",
              "      <td>neutral</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "      <td>24-02-2015 11:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.703010e+17</td>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>24-02-2015 11:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.703010e+17</td>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>24-02-2015 11:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14635</th>\n",
              "      <td>5.695880e+17</td>\n",
              "      <td>positive</td>\n",
              "      <td>@AmericanAir thank you we got on a different f...</td>\n",
              "      <td>22-02-2015 12:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14636</th>\n",
              "      <td>5.695870e+17</td>\n",
              "      <td>negative</td>\n",
              "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
              "      <td>22-02-2015 11:59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14637</th>\n",
              "      <td>5.695870e+17</td>\n",
              "      <td>neutral</td>\n",
              "      <td>@AmericanAir Please bring American Airlines to...</td>\n",
              "      <td>22-02-2015 11:59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14638</th>\n",
              "      <td>5.695870e+17</td>\n",
              "      <td>negative</td>\n",
              "      <td>@AmericanAir you have my money, you change my ...</td>\n",
              "      <td>22-02-2015 11:59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14639</th>\n",
              "      <td>5.695870e+17</td>\n",
              "      <td>neutral</td>\n",
              "      <td>@AmericanAir we have 8 ppl so we need 2 know h...</td>\n",
              "      <td>22-02-2015 11:58</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14640 rows Ã— 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           tweet_id airline_sentiment  \\\n",
              "0      5.703060e+17           neutral   \n",
              "1      5.703010e+17          positive   \n",
              "2      5.703010e+17           neutral   \n",
              "3      5.703010e+17          negative   \n",
              "4      5.703010e+17          negative   \n",
              "...             ...               ...   \n",
              "14635  5.695880e+17          positive   \n",
              "14636  5.695870e+17          negative   \n",
              "14637  5.695870e+17           neutral   \n",
              "14638  5.695870e+17          negative   \n",
              "14639  5.695870e+17           neutral   \n",
              "\n",
              "                                                    text     tweet_created  \n",
              "0                    @VirginAmerica What @dhepburn said.  24-02-2015 11:35  \n",
              "1      @VirginAmerica plus you've added commercials t...  24-02-2015 11:15  \n",
              "2      @VirginAmerica I didn't today... Must mean I n...  24-02-2015 11:15  \n",
              "3      @VirginAmerica it's really aggressive to blast...  24-02-2015 11:15  \n",
              "4      @VirginAmerica and it's a really big bad thing...  24-02-2015 11:14  \n",
              "...                                                  ...               ...  \n",
              "14635  @AmericanAir thank you we got on a different f...  22-02-2015 12:01  \n",
              "14636  @AmericanAir leaving over 20 minutes Late Flig...  22-02-2015 11:59  \n",
              "14637  @AmericanAir Please bring American Airlines to...  22-02-2015 11:59  \n",
              "14638  @AmericanAir you have my money, you change my ...  22-02-2015 11:59  \n",
              "14639  @AmericanAir we have 8 ppl so we need 2 know h...  22-02-2015 11:58  \n",
              "\n",
              "[14640 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1a.2. Using Regex for preprocessing the text"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "source": [
        "df_A['text'].replace(regex=True, inplace=True, to_replace=r'[^A-Za-z0-9 ]+', value=r'')\n",
        "df_A['text'].replace(regex=True, inplace=True, to_replace=r'\\d+\\s*', value=r'')\n",
        "df_A[\"text\"] = df_A[\"text\"].apply(lambda x: x.lower())\n",
        "\n",
        "df_A['text']"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                         virginamerica what dhepburn said\n",
              "1        virginamerica plus youve added commercials to ...\n",
              "2        virginamerica i didnt today must mean i need t...\n",
              "3        virginamerica its really aggressive to blast o...\n",
              "4        virginamerica and its a really big bad thing a...\n",
              "                               ...                        \n",
              "14635    americanair thank you we got on a different fl...\n",
              "14636    americanair leaving over minutes late flight n...\n",
              "14637    americanair please bring american airlines to ...\n",
              "14638    americanair you have my money you change my fl...\n",
              "14639    americanair we have ppl so we need know how ma...\n",
              "Name: text, Length: 14640, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1a.3 Generating the TF-IDF feature matrix"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "source": [
        "processed_reviews = df_A['text']\n",
        "\n",
        "unique_words=[]\n",
        "unique_words_count = []\n",
        "\n",
        "for review in processed_reviews:\n",
        "    for word in review.split():\n",
        "        if word not in unique_words:\n",
        "            unique_words.append(word)\n",
        "            unique_words_count.append(1)\n",
        "        else:\n",
        "            index = unique_words.index(word)\n",
        "            unique_words_count[index] = unique_words_count[index] + 1\n",
        "\n",
        "tfidf_feature_matrix = np.zeros((len(processed_reviews),len(unique_words)))\n",
        "\n",
        "for n,review in enumerate(processed_reviews):\n",
        "    for word in review.split():\n",
        "        index = unique_words.index(word)\n",
        "        tfidf_feature_matrix[n][index] = review.split().count(word) * math.log(len(processed_reviews) / unique_words_count[index])\n",
        "        \n",
        "tfidf_feature_matrix"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.33768398, 3.10078925, 9.59151279, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [3.33768398, 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [3.33768398, 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        9.59151279],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Fit the Log Regression Classifier and get Accuracy, Precision, Recall and AUC Score"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2a. Mapping the airline_sentiment data"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "source": [
        "df = df_A\n",
        "\n",
        "# Mapping values from -1 to 1\n",
        "# Limiting values between 0 and 1 for binary logistic regression\n",
        "\n",
        "df['airline_sentiment'] = df['airline_sentiment'].map({'negative': 0, 'neutral': 1, 'positive': 1})\n",
        "df['airline_sentiment'] = df['airline_sentiment'].astype('category')\n",
        "df.head(10)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_created</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.703060e+17</td>\n",
              "      <td>1</td>\n",
              "      <td>virginamerica what dhepburn said</td>\n",
              "      <td>24-02-2015 11:35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.703010e+17</td>\n",
              "      <td>1</td>\n",
              "      <td>virginamerica plus youve added commercials to ...</td>\n",
              "      <td>24-02-2015 11:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.703010e+17</td>\n",
              "      <td>1</td>\n",
              "      <td>virginamerica i didnt today must mean i need t...</td>\n",
              "      <td>24-02-2015 11:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.703010e+17</td>\n",
              "      <td>0</td>\n",
              "      <td>virginamerica its really aggressive to blast o...</td>\n",
              "      <td>24-02-2015 11:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.703010e+17</td>\n",
              "      <td>0</td>\n",
              "      <td>virginamerica and its a really big bad thing a...</td>\n",
              "      <td>24-02-2015 11:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.703010e+17</td>\n",
              "      <td>0</td>\n",
              "      <td>virginamerica seriously would pay a flight for...</td>\n",
              "      <td>24-02-2015 11:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5.703010e+17</td>\n",
              "      <td>1</td>\n",
              "      <td>virginamerica yes nearly every time i fly vx t...</td>\n",
              "      <td>24-02-2015 11:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5.703000e+17</td>\n",
              "      <td>1</td>\n",
              "      <td>virginamerica really missed a prime opportunit...</td>\n",
              "      <td>24-02-2015 11:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>5.703000e+17</td>\n",
              "      <td>1</td>\n",
              "      <td>virginamerica well i didntbut now i do d</td>\n",
              "      <td>24-02-2015 11:11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>5.702950e+17</td>\n",
              "      <td>1</td>\n",
              "      <td>virginamerica it was amazing and arrived an ho...</td>\n",
              "      <td>24-02-2015 10:53</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       tweet_id airline_sentiment  \\\n",
              "0  5.703060e+17                 1   \n",
              "1  5.703010e+17                 1   \n",
              "2  5.703010e+17                 1   \n",
              "3  5.703010e+17                 0   \n",
              "4  5.703010e+17                 0   \n",
              "5  5.703010e+17                 0   \n",
              "6  5.703010e+17                 1   \n",
              "7  5.703000e+17                 1   \n",
              "8  5.703000e+17                 1   \n",
              "9  5.702950e+17                 1   \n",
              "\n",
              "                                                text     tweet_created  \n",
              "0                   virginamerica what dhepburn said  24-02-2015 11:35  \n",
              "1  virginamerica plus youve added commercials to ...  24-02-2015 11:15  \n",
              "2  virginamerica i didnt today must mean i need t...  24-02-2015 11:15  \n",
              "3  virginamerica its really aggressive to blast o...  24-02-2015 11:15  \n",
              "4  virginamerica and its a really big bad thing a...  24-02-2015 11:14  \n",
              "5  virginamerica seriously would pay a flight for...  24-02-2015 11:14  \n",
              "6  virginamerica yes nearly every time i fly vx t...  24-02-2015 11:13  \n",
              "7  virginamerica really missed a prime opportunit...  24-02-2015 11:12  \n",
              "8           virginamerica well i didntbut now i do d  24-02-2015 11:11  \n",
              "9  virginamerica it was amazing and arrived an ho...  24-02-2015 10:53  "
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2b. Splitting the data into training and test sets and fitting the model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, average_precision_score\n",
        "\n",
        "X = tfidf_feature_matrix\n",
        "\n",
        "y = df_A['airline_sentiment']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
        "\n",
        "lg = LogisticRegression(C=0.5, solver='liblinear', penalty='l1')\n",
        "lg.fit(X_train, y_train)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=0.5, penalty='l1', solver='liblinear')"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "source": [
        "lg_y_pred = lg.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", lg.score(X_test, y_test))\n",
        "print(\"Average precision-recall score\", average_precision_score(y_test, lg_y_pred))\n",
        "print(\"AUC score:\", roc_auc_score(y_test, lg_y_pred))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8306010928961749\n",
            "Average precision-recall score 0.6829619580696455\n",
            "AUC score: 0.8202985034653019\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Compare the result with Naive Bayes"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "bb = BernoulliNB()\n",
        "bb.fit(X_train, y_train)\n",
        "bb_y_pred = bb.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", bb.score(X_test, y_test))\n",
        "print(\"Average precision-recall score\", average_precision_score(y_test, bb_y_pred))\n",
        "print(\"AUC score:\", roc_auc_score(y_test, bb_y_pred))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.833879781420765\n",
            "Average precision-recall score 0.6892610138445917\n",
            "AUC score: 0.8171850404558888\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Observations"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The dataset is imbalanced, as the reviews are largely negative.\n",
        "\n",
        "* The data was split between two, considering negative reviews as `0`, whereas neutral and positive reviews as `1` for binary classification.\n",
        "\n",
        "* The training and test data have been split into training and test sets using the `train_test_split` method.(ratio 3:1)\n",
        "\n",
        "* The model has been fit using Logistic Regression, and the accuracy is reported as `0.830`\n",
        "\n",
        "* The model has been fit using BernoulliNB, and the accuracy is reported as `0.833`\n",
        "\n",
        "* The TF-IDF feature matrix performs better than the BoW matrix by approximately 9.8% accuracy.\n",
        "\n",
        "* BernoulliNB outperforms Logistic Regression in Accuracy as it is better at smaller amounts of data compared to other popular models.\n"
      ],
      "metadata": {}
    }
  ]
}